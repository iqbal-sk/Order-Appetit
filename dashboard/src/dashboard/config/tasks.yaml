schema_analysis_task:
  description: >
    Analyze the data schemas of the 'Order Appetit' application to identify necessary collections and fields required to address the following user query:

    "{user_query}"

    **Context:**
    **Context:**
        - 'Order Appetit' is a local food delivery app in Buffalo.
        - The associated database is named '{database_name}'.
        - Available collections are:
          {collection_names}
    
    **Objective:**
        - Identify necessary collections and fields to address the user query, focusing on specified metrics.
        - Provide all naming variations for queried food items (If query is about food items).
        - Prepare a schema mapping that will be used to construct consistent and comprehensive queries.
    
    **Instructions:**
    1. **Identify Relevant Collections and Fields**:
       - From the provided schemas, determine which collections and fields are necessary to answer the user query.
       - Justify your selection based on their relevance to the query components. If required think again to determine
         necessary fields to answer the user query.
    
    Note: Please note that orders.total_amount is "the total amount on entire order", but not about any specific item in order, 
    for total amount on a single item, you can find that information from "orders.details[].total_amount"
       
    2. **Perform Schema Analysis**:
       - Analyze the schemas of the relevant collections to understand their structure and data types.
       - Identify the data type of each field and its parent field (if applicable).

    3. **Map Query Components**:
       - Break down the user query into key components (e.g., time frame, product name).
       - Map each component to the corresponding collections and fields, emphasizing names over IDs.
       
    4. **Handle Naming Inconsistencies**:
       - When processing a user query, check if it contains any food item names.
       - Use appropriate tool to identify naming inconsistencies for given food items (only if the query is about specific food item).
         Otherwise don't try to find naming inconsistencies.
       - Analyze list of names semantically equivalent to given food item in user_query.

    5. **Document Findings**:
       - Provide a detailed mapping of query components to collections and fields, emphasizing the importance of using names over IDs.
       - Include all naming variations for food items, ensuring comprehensive results.
       - Include any assumptions or considerations made during the analysis.

  expected_output: >
    - A list of relevant collections and fields necessary to answer the user query, with justifications.
    - For each relevant field, provide:
      - Field name
      - Data type
      - Parent field (if applicable)
    - If query is about a specific food item, provide other names to look out for while writing queries for food item in user query.
    - Explanations and any assumptions made during the analysis.

query_building_task:
  description: >
    Generate an optimized MongoDB query or aggregation pipeline to calculate total sales count and sales value in dollars, using names instead of IDs, based on the schema mapping from the `schema_analysis_task`. This should address the following user query:

    "{user_query}"

    **Context:**
    - **Schema Mapping**: Utilize the output from the `schema_analysis_task`, including strategies for handling naming inconsistencies.
    - **MongoDB URI**: {mongodb_uri}
    - **Database Name**: {database_name}
    - **Collections**: {collection_names}
    
    **Objective:**
        - Create an optimized MongoDB query that includes all relevant records by addressing naming inconsistencies.
        - Deliver Python code that outputs results as a JSON object for comprehensive analysis.

    **Instructions:**
    1. **Utilize Schema Mapping**:
       - Refer to the schema mapping to identify relevant collections and fields to get better idea for yourself.
       - Incorporate naming variations from the schema analysis (as it is, without any changes) to handle inconsistencies in product names.

    2. **Construct the Query**:
       - Build a MongoDB aggregation pipeline using proper MongoDB syntax and operators.
       - Properly implement variable handling in the pipeline.
       - Use `unwind` if necessary for array fields to ensure accurate calculations.
       - For name matching, use case-insensitive comparison by converting both the field value and the reference value to
         lowercase using the `$toLower` operator. 
       - Include names (e.g., product names, restaurant names) in the results instead of IDs.

    3. **Optimize for Performance**:
       - Apply best practices for handling large datasets efficiently.
       - Ensure efficient grouping and summing operations.

    4. **Implement in Python**:
       - Write executable Python code using PyMongo to connect to MongoDB and execute the query.
       - Ensure the code returns results as a JSON object with sales count and sales value per item name.


  expected_output: >
    You MUST return a JSON object containing:
    - python_code: Executable code that connects to MongoDB and runs the optimized query, returning results as a JSON object.
    - query_output_structure: Description of the expected output format, including fields and data types.

  agent: query_builder
  context:
    - schema_analysis_task

data_analysis_task:
  description: >
    Execute the MongoDB query generated in the `query_building_task` and present the output in a granular and tabular format, ensuring consistency and use of names instead of IDs, for the following user query:

    **User Query**: "{user_query}"

    **Context:**
    - **MongoDB URI**: "{mongodb_uri}"
    - **Database Name**: "{database_name}"
    - **Query Code**: Use the Python code from the `query_building_task`.
    - **Schema Mapping**: Refer to outputs from the `schema_analysis_task`.

    **Objective:**
    - Analyze the provided code if it's correct, if not please modify it accordingly.
    - Execute the MongoDB query and return the results in a detailed, granular, and tabular format.
    - Ensure all relevant records are included, using names instead of IDs.

    **Instructions:**
    1. **Execute the Query**:
       - Correct and format the provided Python code correctly.
       - Pass any necessary arguments to the Code Execution Tool.
       - Run the Python code to execute the query and capture the JSON output.

    2. **Understand JSON Results**:
       - Transform JSON output into a structured format
       - Verify the data for completeness and correctness.

    3. **Format the Results**:
       - Present the output in a granular tabular format.
       - Ensure the table includes all necessary fields (e.g., names, quantities, sales values) with clear column labels.
       - Maintain consistency in naming conventions as per the schema mapping.

    4. **Output Presentation**:
       - Display the tabular results clearly, ensuring they are sorted appropriately if needed.
       - Avoid any additional analysis or interpretationâ€”focus solely on presenting the data.
   
    

  expected_output: >
    - If you didn't get appropriate output from tool, provide apology message but don't hallucinate stuff.
    - A detailed, granular table of query results with fields like names, quantities, and sales values.
    - Results must use names (not IDs) and align with schema mapping outputs.
    - Include clear column headers and consistent formatting.

  agent: data_analyst
  context:
    - query_building_task
    - schema_analysis_task
